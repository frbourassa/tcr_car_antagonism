{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Universal antagonism classification on MSKCC peptide libraries\n",
    "\n",
    "## Revised EC50 fits on the dose response data\n",
    "As explained in the supplemental information section \"II.3.9 Antagonism predictions for mutated peptide libraries\", we had to perform our own EC50 fits on the dose response data from the paper \n",
    "\n",
    "> Łuksza *et al*., \"Neoantigen quality predicts immunoediting in survivors of pancreatic cancer\", *Nature*, 2022. \n",
    "\n",
    "The motivation was threefold: to ensure a consistent treatment with our own dose response measurements on the HHAT peptide library, to obtain error bars on the fitted EC50s, and to use the same parameter clipping boundaries on all peptide sets (derived from CMV, gp100, and a neoantigen). \n",
    "\n",
    "The script `secondary_scripts/mskcc_ec50_mcmc.py` generated these EC50 fits. Here, we additionally need to fix missing EC50s for all the weakest CMV-derived peptides, which only had their response at maximum dose measured. Discarding these peptides would create a systematic under-estimation of the fraction of potential antagonist peptides. We prevent this issue (as explained in the SI) by inferring the missing EC50s from a linear regression between the EC50 and the response at maximum dose: we perform the linear fit on all peptides for which a full dose response is available, then use the regression to infer the EC50 of missing peptides based on their maximal response. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting antagonism\n",
    "Once we have an EC50 for all peptides, we convert them to $\\tau$s and use the revised AKPR model to predict the antagonism or enhancement each peptide would cause. We set antigen abundances $L^\\rho$ based on measurements of CAR antigen and MHC abundance on the target tumor cells, here assumed to be PC9 tumors. \n",
    "\n",
    "## Strategy to generate complete prediction confidence intervals\n",
    "\n",
    "We will propagate the following sources of uncertainty to these model predictions in particular, since there is no experimental data to confirm the model $FC$ predictions, so we want to convey the high level of uncertainty associated with these predictions, beyond just uncertainty on the best model parameter fits. \n",
    "\n",
    "- TCR/CAR model parameters: from MCMC samples of revised AKPR model parameter fits\n",
    "- Antigen densities: assume log-normal distributions around the \"average APC\" on which the ODE model is based. The standard deviation of this distribution is the standard error on the statistical mean estimator. \n",
    "- Peptide affinities: from a log-normal fit on the MCMC distribution of dose response curve parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import json, h5py\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from utils.cpu_affinity import count_parallel_cpu\n",
    "from utils.fitting import hill_with_back_diff\n",
    "n_cpu = count_parallel_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocess import michaelis_menten\n",
    "from models.conversion import convert_ec50_tau_relative\n",
    "from mcmc.plotting import change_log_ticks\n",
    "from utils.preprocess import write_conc_uM\n",
    "from mcmc.costs_tcr_car_antagonism import antag_ratio_panel_tcr_car\n",
    "from mcmc.ci_predictions_molec_numbers import (\n",
    "    confidence_predictions_car_antagonism_ligands,\n",
    "    compute_stats_ci\n",
    ")\n",
    "from mcmc.utilities_tcr_car_antagonism import load_tcr_car_molec_numbers_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 10 for quick test run, 1000 for adequate statistics\n",
    "n_boot = 1000\n",
    "do_save_plots = False\n",
    "do_save_outputs = False\n",
    "\n",
    "# Plot parameters\n",
    "fig_dir_supp = os.path.join(\"figures\", \"dose_response\", \"mskcc_fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aesthetic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/for_plots/perturbations_palette.json\", \"r\") as f:\n",
    "    perturb_palette = json.load(f)\n",
    "perturb_palette[\"None\"] = [0., 0., 0., 1.]  # Black\n",
    "sns.palplot(perturb_palette.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: reanalyze MSKCC EC50 to obtain error bars on EC50\n",
    "Will use the same least-squares fitting function detailed in their supplementary information, and will use the jacobian of that cost function at the best fit point to estimate a standard deviation on the EC50 (diagonal element of the inverse jacobian is the variance). \n",
    "\n",
    "## Done with MCMC\n",
    "\n",
    "There are 1204 peptides, $32 \\times 1000$ MCMC parameter samples for each: huge same file. The resulting distribution for EC50 is approximately Gaussian in log scale, so I have just fitted the standard deviation of this marginal posterior distribution, and for CI calculation will sample log-normal values of EC50 from this approximate distribution\n",
    "\n",
    "Using the maximum a posteriori for the best model prediction line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit results\n",
    "df_ec50_stats = pd.read_hdf(os.path.join(\"results\", \"pep_libs\", \"mskcc_ec50_mcmc_stats_backgnd.h5\"), key=\"df\")\n",
    "df_ec50_stats = df_ec50_stats.sort_index(axis=1).drop([\"mcmc_tau\", \"logprob\"], axis=1)\n",
    "\n",
    "df_ec50_lsq3 = pd.read_hdf(os.path.join(\"results\", \"pep_libs\", \"mskcc_ec50_lsq_results_backgnd_3.h5\"), key=\"df\")\n",
    "df_ec50_lsq3 = df_ec50_lsq3.drop([\"V_inf_std\", \"n_std\", \"log_ec50_ugmL_std\", \"K_a\"], axis=1)\n",
    "df_ec50_lsq3 = pd.concat({\"LSQ_3\":df_ec50_lsq3.sort_index(axis=1)}, names=[\"Feature\", \"Parameter\"], axis=1)\n",
    "\n",
    "# Least-squares of the same full model as the MCMC simulations, to get meaningful\n",
    "# Hessian estimates of parameter uncertainty\n",
    "param_names5 = [\"V_inf\", \"n\", \"log_ec50_ugmL\", \"logN_eff\", \"backgnd\"]\n",
    "stds_names5 = [a+\"_std\" for a in param_names5]\n",
    "rename_map = dict(zip(stds_names5, param_names5))\n",
    "df_ec50_lsq5 = pd.read_hdf(os.path.join(\"results\", \"pep_libs\", \"mskcc_ec50_lsq_results_backgnd_5.h5\"), key=\"df\")\n",
    "df_ec50_lsq5 = pd.concat({\"LSQ_5\":df_ec50_lsq5[param_names5], \"std_lsq\":df_ec50_lsq5[stds_names5].rename(rename_map, axis=1)}, \n",
    "                         names=[\"Feature\", \"Parameter\"], axis=1)\n",
    "df_ec50_stats = pd.concat([df_ec50_stats, df_ec50_lsq3, df_ec50_lsq5], axis=1)\n",
    "\n",
    "# Can drop everything except EC50, other code has already plotted sample fits to check quality. \n",
    "#df_ec50_stats = df_ec50_stats.xs(\"log_ec50_ugmL\", axis=1, level=\"Parameter\")\n",
    "df_ec50_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_raw_data_mskcc = pd.read_hdf(os.path.join(\"data\", \"dose_response\", \"MSKCC_rawDf.hdf\"), key=\"df\")\n",
    "df_dose_mskcc = df_raw_data_mskcc.set_index([\"Dose (ug/mL)\"],\n",
    "                drop=True, append=True).drop(\"Dose (M)\", axis=1)\n",
    "df_dose_mskcc = df_dose_mskcc.unstack([\"Dose (ug/mL)\"]) / 100.0\n",
    "resp_name = \"Response (CD137+ fraction)\"\n",
    "df_dose_mskcc = df_dose_mskcc.rename(\n",
    "    {\"Response (CD137+ %)\": resp_name}, axis=1)\n",
    "df_dose_mskcc[resp_name] = df_dose_mskcc[resp_name].clip(0.0, 1.0)\n",
    "df_dose_mskcc = df_dose_mskcc.sort_index()\n",
    "\n",
    "tcr_set = df_dose_mskcc.index.get_level_values(\"TCR\").unique().sort_values()\n",
    "tcr_to_ag_map = {}\n",
    "for tcr in tcr_set: \n",
    "    tcr_to_ag_map[tcr] = df_dose_mskcc.xs(tcr, level=\"TCR\").index.get_level_values(\"Antigen\")[0]\n",
    "print(tcr_to_ag_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot difference between our fits and the original ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_identity_for_wt(df):\n",
    "    \"\"\" For a DataFrame of peptides, for each TCR, change a\n",
    "    peptide which is unmutated for 'WT' and drop duplicates \"\"\"\n",
    "    df2 = df.copy()\n",
    "    for ag, tcr, pep in df.index:\n",
    "        if pep[0] == pep[2]:  # This is WT\n",
    "            df2 = df2.rename({pep:\"WT\"}, level=\"Peptide\", axis=0)\n",
    "            \n",
    "    df2 = df2.loc[~df2.index.duplicated(keep='first')].sort_index()\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare fit results to those provided by MSKCC\n",
    "df_fits_mskcc = pd.read_hdf(\"data/dose_response/MSKCC_fitCurvesEC50.hdf\", key=\"df\")\n",
    "df_fits_mskcc[np.isinf(df_fits_mskcc)] = np.nan\n",
    "# They say they clip and they provide large values... There is some crap for sure in that dataset\n",
    "df_fits_mskcc[\"K_a\"] = df_fits_mskcc[\"K_a\"].clip(lower=1e-4, upper=1e4)\n",
    "df_fits_mskcc[\"log_ec50_ugmL\"] = np.log10(df_fits_mskcc[\"K_a\"])\n",
    "df_fits_mskcc = df_fits_mskcc.rename({\"A\":\"V_inf\"}, axis=1)\n",
    "df_fits_mskcc = df_fits_mskcc.rename({\"Neopeptide\":\"Neoantigen\"}, axis=0, level=\"Antigen\")\n",
    "p_keep = [\"V_inf\", \"n\", \"K_a\", \"log_ec50_ugmL\"]\n",
    "df_fits_mskcc = df_fits_mskcc[p_keep]\n",
    "df_fits_mskcc = change_identity_for_wt(df_fits_mskcc)\n",
    "df_fits_mskcc.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ours_theirs = pd.concat({\"ours\":df_ec50_stats[\"MAP\"], \"theirs\":df_fits_mskcc}, axis=1, names=[\"Source\"])\n",
    "df_ours_theirs = df_ours_theirs.sort_index(axis=1).sort_index(axis=0)\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, sharey=\"row\")\n",
    "fig.set_size_inches(6, 9)\n",
    "xlabels = [\"theirs\", \"ours\"]\n",
    "for i, p in enumerate([\"log_ec50_ugmL\", \"V_inf\", \"n\"]):\n",
    "    yvals = df_ours_theirs.xs(p, level=\"Parameter\", axis=1).dropna()\n",
    "    axes[i, 0].plot(\n",
    "        np.arange(2).reshape(2, 1), yvals[xlabels].values.T, \n",
    "        ls=\"-\", color=\"grey\", lw=0.5\n",
    "    )\n",
    "    npeps = yvals.shape[0]\n",
    "    axes[i, 0].plot(np.zeros(npeps), yvals[xlabels[0]].values, marker=\"o\", color=\"k\", ms=4, alpha=0.7)\n",
    "    axes[i, 0].plot(np.ones(npeps), yvals[xlabels[1]].values, marker=\"o\", color=\"r\", ms=4, alpha=0.7)\n",
    "    axes[i, 0].set_xticks(np.arange(2))\n",
    "    axes[i, 0].set_xticklabels(xlabels)\n",
    "    axes[i, 0].set_ylabel(p)\n",
    "    \n",
    "    # Now histograms or KDEs\n",
    "    hist_ours, edges_ours = np.histogram(yvals[\"ours\"].values, bins=20)\n",
    "    hist_theirs, edges_theirs = np.histogram(yvals[\"theirs\"].values, bins=20)\n",
    "    axes[i, 1].barh(y=edges_theirs[:-1], width=hist_theirs, height=np.diff(edges_theirs), \n",
    "                    align=\"edge\", color=\"k\", alpha=0.7, label=\"theirs\")\n",
    "    axes[i, 1].barh(y=edges_ours[:-1], width=hist_ours, height=np.diff(edges_ours), \n",
    "                    align=\"edge\", color=\"r\", alpha=0.7, label=\"ours\")\n",
    "    axes[i, 1].legend()\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One example where their EC50 and ours are very different. \n",
    "# But this is a very weak peptide, response near zero, so \n",
    "# the EC50 should be large: ours is better. \n",
    "df_ours_theirs.loc[(\"gp100\", \"6\", \"V9S\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Convert EC50s in mass/volume to EC50s in molar units\n",
    "Also convert the standard deviations (error bars). \n",
    "\n",
    "Sooraj did (in Colab) the calculation for each peptide using molecular weights of amino acids; I can just compare the Dose (M) and Dose (ug/mL) values for each peptide in the raw Df and infer the scaling factor for each peptide separately. \n",
    "\n",
    "Neglecting any uncertainty on these factors and on the molecular weights, they are negligible compared to biological and parameter estimation sources of uncertainty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_ratio = df_raw_data_mskcc.set_index(\"Dose (ug/mL)\", append=True, drop=False)\n",
    "weight_conv_factors = df_for_ratio[\"Dose (M)\"] / df_for_ratio['Dose (ug/mL)']\n",
    "weight_conv_factors = weight_conv_factors.xs(100.0, level=\"Dose (ug/mL)\")\n",
    "print(\"Number of unique conversion factors:\", np.unique(weight_conv_factors.dropna().values).size)\n",
    "print(\"Versus number of peptides with ug/ML EC50s:\", weight_conv_factors.dropna().shape[0])\n",
    "weight_conv_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lvl in df_ec50_stats.columns.get_level_values(\"Feature\").unique():\n",
    "    # log(K * factor) = log(K) + log(factor). Base is log_10\n",
    "    # Standard deviation in log-scale remains the same: log(ugml * scale) = log(ugml) + constant\n",
    "    # the constant does not contribute to the standard deviation\n",
    "    if lvl == \"stdev\" or lvl == \"std_lsq\": \n",
    "        df_ec50_stats.loc[:, (lvl, \"log_ec50_M\")] = df_ec50_stats.loc[:, (lvl, \"log_ec50_ugmL\")]\n",
    "    else:\n",
    "        df_ec50_stats.loc[:, (lvl, \"log_ec50_M\")] = (df_ec50_stats.loc[:, (lvl, \"log_ec50_ugmL\")]\n",
    "                                                    + np.log10(weight_conv_factors))\n",
    "df_ec50_stats.sort_index(axis=1).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.3 Apply correction based on max response for missing EC50s \n",
    "\n",
    "Important bias: the 2022 paper did not measure full EC50 curves for all CMV-derived peptides (and only for CMV) with response below ~50 % at max. dose. This removes most potential antagonists and severely biases the distribution. **It is not fair to set these peptides to infinite EC50 as if they were null, because they do produce a lot of response**. So, we need to correct these missing EC50s, or drop CMV altogether. \n",
    "\n",
    "For these peptides with only one dose tested, we can infer EC50 (in M) without fitting a Hill curve by regressing the max response against the EC50 for fitted peptides, then using this linear regression fit to estimate the EC50 of peptides with only one max. dose response. \n",
    "\n",
    "Give these peptides a bigger uncertainty, based on the linear regression uncertainty: yet another propagation step, this gets complicated even statistically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get a CI on the inferred EC50s\n",
    "from utils.fitting import (\n",
    "    student_t_predict_interval_linregress, \n",
    "    student_t_confid_interval_linregress\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustrating the bias that missing EC50s are all for the weakest peptides. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mut2 = df_fits_mskcc[\"K_a\"]\n",
    "df_mut2.name = \"ec50_M\"\n",
    "df_mut2 = df_mut2.to_frame()\n",
    "\n",
    "peps_with_inf = np.isnan(df_mut2)\n",
    "df_plot = df_raw_data_mskcc.copy().xs(\"CMV\", level=\"Antigen\")\n",
    "df_plot[\"not_measured_inf\"] = peps_with_inf.xs(\"CMV\", level=\"Antigen\")\n",
    "\n",
    "ec50_threshold_antagonists = 1e-3\n",
    "avg_max_response_antagonists = df_mut2[df_mut2[\"ec50_M\"] < ec50_threshold_antagonists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.ecdfplot(data=df_plot.loc[df_plot[\"Dose (ug/mL)\"] == 100.0].reset_index(), \n",
    "             x=\"Response (CD137+ %)\", hue=\"not_measured_inf\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting EC50s vs maximum response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_ec = \"log_ec50_M\"  #\"EC50 (M)\"  #'EC50 (ug/mL)'\n",
    "choice_method = \"MAP\"\n",
    "choice_std = \"std_lsq\" if choice_method.startswith(\"LSQ\") else \"stdev\"\n",
    "if choice_ec == 'log_ec50_M':\n",
    "    noINF = df_ec50_stats[(choice_method, choice_ec)].copy()\n",
    "elif choice_ec == \"EC50 (ug/mL)\":\n",
    "    noINF = df_fits_mskcc.copy()[\"K_a\"]\n",
    "elif choice_ec == \"EC50 (M)\":\n",
    "    noINF = df_fits_mskcc.copy()[\"K_a\"] * weight_conv_factors\n",
    "noINF.name = choice_ec\n",
    "\n",
    "noINF2 = df_raw_data_mskcc[df_raw_data_mskcc['Dose (ug/mL)'] == 100]\n",
    "noINF = pd.concat([noINF,noINF2],axis=1)\n",
    "noINF = noINF[~np.isnan(noINF[choice_ec])]\n",
    "if choice_ec.startswith(\"log\"):\n",
    "    noINF[\"EC50 (M)\"] = 10.0**noINF[choice_ec]\n",
    "noINF = noINF[noINF[choice_ec] != np.inf]\n",
    "noINF = noINF.rename({\"Response (CD137+ %)\": resp_name}, axis=1)\n",
    "noINF[resp_name] /= 100.0\n",
    "noINF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plottingDf = noINF.copy()\n",
    "plottingDf[resp_name] = np.clip(plottingDf[resp_name],a_min=0,a_max=1.0)\n",
    "if choice_ec == \"EC50 (ug/mL)\":\n",
    "    plottingDf[choice_ec] = np.clip(plottingDf[choice_ec],a_min=-np.inf,a_max=1e5)\n",
    "    #plottingDf = plottingDf[plottingDf['EC50 (M)'] <= 10**5]\n",
    "elif choice_ec == \"EC50 (M)\":\n",
    "    plottingDf[choice_ec] = np.clip(plottingDf[choice_ec],a_min=-np.inf,a_max=1e5*weight_conv_factors.mean())\n",
    "\n",
    "X = plottingDf[resp_name].values.reshape(-1,1)\n",
    "if choice_ec.startswith(\"log\"):\n",
    "    y = plottingDf[choice_ec].values.reshape(-1,1)\n",
    "elif choice_ec.startswith(\"EC50\"):\n",
    "    y = np.log10(plottingDf[choice_ec].values.reshape(-1,1))\n",
    "reg = LinearRegression().fit(X, y)\n",
    "regscore = reg.score(X, y)\n",
    "y_label = (r\"EC$_{50}$ (M)\" if (choice_ec.endswith(\"M\") or choice_ec.endswith(\"M)\"))\n",
    "        else r\"EC$_{50}$ (ug/mL)\")\n",
    "y_feature = \"EC50 (M)\" if choice_ec in [\"log_ec50_M\", \"EC50 (M)\"] else \"EC50 (ug/mL)\"\n",
    "g = sns.relplot(data=plottingDf,x=resp_name,y=y_feature, s=25)\n",
    "g.set(yscale='log', xlabel=r\"4-1BB$^+$ % at max dose\",\n",
    "      ylabel=y_label)\n",
    "# Plot the regression line too\n",
    "xrange = np.linspace(X.min(), X.max(), 200)\n",
    "yrange = 10.0**(reg.coef_[0]*xrange + reg.intercept_)\n",
    "g.ax.plot(xrange, yrange, color=\"k\")\n",
    "g.ax.annotate(r\"$R^2 = {:.2f}$\".format(regscore), xy=(0.95, 0.9),\n",
    "              xycoords=\"axes fraction\", ha=\"right\", va=\"center\")\n",
    "print(regscore)\n",
    "\n",
    "# Also show the confidence interval (not the prediction interval) of the fit\n",
    "mean_x = X.mean()\n",
    "sum_x_resids = np.sum((X - mean_x)**2)\n",
    "sample_vari_fit = np.sum((y - reg.predict(X))**2) / (X.size - 2)\n",
    "confid = student_t_confid_interval_linregress(\n",
    "    x=xrange, alpha=0.05, ndf=X.size, mean_x_estim=mean_x, vari_estim=sample_vari_fit, \n",
    "    ssx=sum_x_resids, slope=reg.coef_[0], intercept=reg.intercept_\n",
    ")\n",
    "pred = student_t_predict_interval_linregress(\n",
    "    x=xrange, alpha=0.05, ndf=X.size, mean_x_estim=mean_x, vari_estim=sample_vari_fit, \n",
    "    ssx=sum_x_resids, slope=reg.coef_[0], intercept=reg.intercept_\n",
    ")\n",
    "\n",
    "y_confid_lo = reg.coef_[0]*xrange + reg.intercept_ - confid\n",
    "y_confid_up = y_confid_lo + 2*confid\n",
    "y_pred_lo = reg.coef_[0]*xrange + reg.intercept_ - pred\n",
    "y_pred_up = y_pred_lo + 2*pred\n",
    "g.ax.fill_between(xrange, 10.0**y_pred_lo, 10.0**y_pred_up, color=\"grey\", alpha=0.4)\n",
    "g.ax.fill_between(xrange, 10.0**y_confid_lo, 10.0**y_confid_up, color=\"k\", alpha=0.2)\n",
    "\n",
    "g.figure.set_size_inches(3, 3)\n",
    "g.figure.tight_layout()\n",
    "if do_save_plots:\n",
    "    g.figure.savefig(os.path.join(fig_dir_supp, \"supfig_maxresponse_vs_ec50s.pdf\"),\n",
    "                    transparent=True, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the linear regression data and parameters for Sooraj\n",
    "X = plottingDf[resp_name]\n",
    "if choice_ec.startswith(\"log\"):\n",
    "    y = plottingDf[choice_ec]\n",
    "    ylbl = choice_ec\n",
    "elif choice_ec.startswith(\"EC50\"):\n",
    "    y = np.log10(plottingDf[choice_ec])\n",
    "    ylbl = \"log_\" + choice_ec\n",
    "regressionDf = pd.concat({resp_name:X, ylbl:y}, axis=1, names=[\"Variable\"])\n",
    "regressionFName = os.path.join(\"results\", \"pep_libs\", \"mskcc_ec50s_maxresponse_regression.h5\")\n",
    "if do_save_outputs:\n",
    "    regressionDf.to_hdf(regressionFName, key=\"data\")\n",
    "\n",
    "# Save the linear regression parameters too\n",
    "paramsSeries = pd.Series([reg.coef_[0, 0], reg.intercept_[0]], \n",
    "    index=pd.Index([\"slope\", \"intercept\"], name=\"Parameter\"), name=\"regression\")\n",
    "paramsSeries\n",
    "if do_save_outputs:\n",
    "    paramsSeries.to_hdf(regressionFName, key=\"regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferring missing EC50s\n",
    "Use the prediction confidence interval of the linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if choice_ec == 'log_ec50_M':\n",
    "    withINF = df_ec50_stats[(choice_method, choice_ec)].copy()\n",
    "elif choice_ec == \"EC50 (ug/mL)\":\n",
    "    withINF = df_fits_mskcc.copy()[\"K_a\"]\n",
    "elif choice_ec == \"EC50 (M)\":\n",
    "    withINF = df_fits_mskcc.copy()[\"K_a\"] * weight_conv_factors\n",
    "withINF.name = choice_ec\n",
    "\n",
    "withINF2 = df_raw_data_mskcc[df_raw_data_mskcc['Dose (ug/mL)'] == 100]\n",
    "withINF = pd.concat([withINF,withINF2],axis=1)\n",
    "withINF = withINF[np.isnan(withINF[choice_ec])]\n",
    "if choice_ec.startswith(\"log\"):\n",
    "    withINF[\"EC50 (M)\"] = 10.0**withINF[choice_ec]\n",
    "withINF = withINF.rename({\"Response (CD137+ %)\": resp_name}, axis=1)\n",
    "withINF[resp_name] /= 100.0\n",
    "\n",
    "withINF[choice_ec] = reg.coef_[0]*withINF[resp_name] + reg.intercept_\n",
    "# Get a CI, divide by the Student's t critical value to get the std\n",
    "withINF[choice_ec + \"_log_std\"] = student_t_predict_interval_linregress(\n",
    "    withINF[choice_ec], 0.05, ndf=X.size, mean_x_estim=mean_x, vari_estim=sample_vari_fit, \n",
    "    ssx=sum_x_resids, slope=reg.coef_[0], intercept=reg.intercept_)\n",
    "withINF[choice_ec + \"_log_std\"]  /= sp.stats.t.ppf(q=1.0 - 0.05/2.0, df=X.size-2)\n",
    "if choice_ec.startswith(\"EC50\"):\n",
    "    withINF[choice_ec] = 10.0**withINF[choice_ec]\n",
    "else:\n",
    "    withINF[\"EC50 (M)\"] = 10.0**withINF[choice_ec]\n",
    "display(withINF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put back the results in the stats dataframe\n",
    "df_ec50_stats_treat = df_ec50_stats.copy()\n",
    "df_ec50_stats_treat.loc[withINF.index, (choice_method, choice_ec)] = withINF[choice_ec]\n",
    "df_ec50_stats_treat.loc[withINF.index, (choice_std, choice_ec)] = withINF[choice_ec + \"_log_std\"]\n",
    "# Also put back the ug/mL corresponding EC50s\n",
    "df_ec50_stats_treat.loc[withINF.index, (choice_method, \"log_ec50_ugmL\")] = (\n",
    "    df_ec50_stats_treat.loc[withINF.index, (choice_method, \"log_ec50_M\")] \n",
    "    - np.log10(weight_conv_factors.loc[withINF.index])\n",
    ")\n",
    "\n",
    "# Also set the maximum response as the amplitude, and background to zero, n to 1, N_eff to 1e3 (large error)\n",
    "df_ec50_stats_treat.loc[withINF.index, (choice_method, \"backgnd\")] = 0.0\n",
    "df_ec50_stats_treat.loc[withINF.index, (choice_method, \"V_inf\")] = withINF[resp_name]\n",
    "df_ec50_stats_treat.loc[withINF.index, (choice_method, \"n\")] = 1.0\n",
    "df_ec50_stats_treat.loc[withINF.index, (choice_method, \"logN_eff\")] = 3\n",
    "df_ec50_stats_treat = df_ec50_stats_treat.sort_index(axis=0).sort_index(axis=1)\n",
    "df_ec50_stats_treat[choice_method]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Ensure non-responsive peptides are either null or antagonists\n",
    "In lack of a measurable dose response, it's impossible to tell whether a peptide will be an antagonist or a completely null peptide. \n",
    "\n",
    "So, for peptides with maximum response too small, or amplitude of response above background too small, or EC50 very close to the maximum, set their EC50 half-way between a completely null EC50 (ensuring $\\tau \\approx 0$) and their fitted EC50, and increase their standard deviation such that when sampling EC50s, they can be either antagonists or null. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-responsive peptides: max response < 15 % (which is the max. background)\n",
    "# and difference in response between min and max doses (in the curve fit) < 0.02\n",
    "max_ec50_found = df_ec50_stats[(choice_method, \"log_ec50_ugmL\")].max()\n",
    "max_ec50_found_M = df_ec50_stats[(choice_method, \"log_ec50_M\")].max()\n",
    "p_best_fits = df_ec50_stats.loc[:, (choice_method, [\"V_inf\", \"n\", \"log_ec50_ugmL\", \"backgnd\"])]\n",
    "resp_difference = pd.Series(0.0, index=df_ec50_stats.index)\n",
    "max_resp = pd.Series(0.0, index=df_ec50_stats.index)\n",
    "for k in resp_difference.index:\n",
    "    max_resp.loc[k] = hill_with_back_diff(2.0, p_best_fits.loc[k].values)\n",
    "    resp_difference.loc[k] = max_resp.loc[k] - hill_with_back_diff(-2.0, p_best_fits.loc[k].values)\n",
    "\n",
    "# Compute a list of non-responsive peptides based on the following criteria\n",
    "resp_difference_thresh = 0.04  # Error bar I used, makes sense as a threshold\n",
    "max_resp_thresh = 0.2\n",
    "no_response_peps = ((resp_difference < resp_difference_thresh) & (max_resp < max_resp_thresh))\n",
    "#    & (df_ec50_stats.loc[:, (choice_method, \"log_ec50_ugmL\")] > (max_ec50_found - 1.0)))\n",
    "\n",
    "print(\"Max log10(EC50):\", max_ec50_found, \"ug/mL\")\n",
    "print(\"Max log10(EC50) in M:\", max_ec50_found_M, \"M\")\n",
    "#print(\"Found {} null peptides\".format(no_response_peps.sum()), \n",
    "#      \"with EC50 near max. and difference in response < 1 % cells\")\n",
    "print(\"Found {} null peptides\".format(no_response_peps.sum()), \n",
    "      \"with max. response < {} %\".format(100.0 * max_resp_thresh), \n",
    "      \"and difference in response < {} % cells\".format(100.0*resp_difference_thresh))\n",
    "print(\"Setting their EC50 to a large value ensuring their tau < 0.1 s\")\n",
    "print(\"And setting the std of these EC50s to a correspondingly large value\")\n",
    "\n",
    "# Treat these peptides\n",
    "do_treat_null = True\n",
    "if do_treat_null:\n",
    "    max_null_ec50 = 3.0\n",
    "    new_null_ec50 = 0.5 * (max_null_ec50 + df_ec50_stats.loc[no_response_peps, (choice_method, \"log_ec50_M\")])\n",
    "    #new_null_ec50 = max_null_ec50\n",
    "    df_ec50_stats_treat.loc[no_response_peps, (choice_method, \"log_ec50_M\")] = new_null_ec50\n",
    "    df_ec50_stats_treat.loc[no_response_peps, (choice_method, \"log_ec50_ugmL\")] = (\n",
    "        new_null_ec50 - np.log10(weight_conv_factors.loc[no_response_peps]))\n",
    "\n",
    "    # The original fit and the max EC50 are both two standard deviations away from the assigned value.  \n",
    "    diff_to_fit = (max_null_ec50 - new_null_ec50) * 0.5\n",
    "    df_ec50_stats_treat.loc[no_response_peps, (choice_std, \"log_ec50_M\")] = np.abs(diff_to_fit)\n",
    "    df_ec50_stats_treat.loc[no_response_peps, (choice_std, \"log_ec50_ugmL\")] = np.abs(diff_to_fit)\n",
    "df_ec50_stats_treat[\"MAP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the final dose response fits\n",
    "Including the missing, inferred EC50s. These fits will be worse, but just checking that there is nothing ludicrous coming out of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hill_norm(x, p3):\n",
    "    a, n, k = p3\n",
    "    return a / (1.0 + 10.0 ** (n * (k - x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_wt_pep_seq(mut_pep_set):\n",
    "    # Remove \"WT\", not useful to reconstruct sequence\n",
    "    try:\n",
    "        mut_pep_set.remove(\"WT\")\n",
    "    except:\n",
    "        pass\n",
    "    # From the list of all peptide mutants in form XiY, keep just the Xi\n",
    "    # elements, which indicate amino acid X is at position i-1 in WT sequence\n",
    "    pep_marks = np.unique(list(map(lambda x: x[:2], mut_pep_set)))\n",
    "    wt_pep_seq = [\"\"] * len(pep_marks)\n",
    "    for m in pep_marks:\n",
    "        aa, pos = m[0], int(m[1]) - 1\n",
    "        if wt_pep_seq[pos] != \"\":\n",
    "            raise ValueError(\"Conflicting amino acids in position\"\n",
    "                +\"{}: {} and {}\".format(pos, aa, wt_pep_seq[pos])\n",
    "            )\n",
    "        else:\n",
    "            wt_pep_seq[pos] = aa\n",
    "    return \"\".join(wt_pep_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the LSQ or MAP fits and the data\n",
    "def full_plots_fits(df_data, df_fit, pep_name=\"\"):\n",
    "    \"\"\" Plot all TCRs and peptides for one antigen \"\"\"\n",
    "    # Prepare line styles\n",
    "    amino_acids = np.unique(list(\"\".join(df_data.index.get_level_values(\"Peptide\").unique())))\n",
    "    amino_acids = sorted([a for a in amino_acids if a.isalpha()])\n",
    "    colors = sns.color_palette(n_colors=len(amino_acids))\n",
    "    colors = {amino_acids[i]:colors[i] for i in range(len(amino_acids))}\n",
    "    colors[\"WT\"] = (0.0,)*3  # black for WT\n",
    "    lstyles = {amino_acids[i]:(\"-\" if i < 10 else \"--\") for i in range(len(amino_acids))}\n",
    "    lstyles[\"WT\"] = \"-\"\n",
    "    markers = {amino_acids[i]:(\"o\" if i < 10 else \"^\") for i in range(len(amino_acids))}\n",
    "    markers[\"WT\"] = \"s\"\n",
    "    \n",
    "    tcr_subset = df_data.index.get_level_values(\"TCR\").unique().sort_values()\n",
    "    x_doses = np.log10(df_data.columns.get_level_values(\"Dose (ug/mL)\").astype(float).values)\n",
    "    \n",
    "    sub_col_map = {}\n",
    "    all_mut_peps = list(df_fit.index.get_level_values(\"Peptide\").unique())\n",
    "    wt_pep_seq = recover_wt_pep_seq(all_mut_peps)\n",
    "    n_rows = len(tcr_subset)\n",
    "    n_cols = len(wt_pep_seq)\n",
    "    resp_name = \"Response (% CD137+)\"\n",
    "    \n",
    "    # Determine Hill model fitted\n",
    "    if \"backgnd\" in df_fit.columns:\n",
    "        dose_fct = hill_with_back_diff\n",
    "        param_names = [\"V_inf\", \"n\", \"log_ec50_ugmL\", \"backgnd\"]\n",
    "    else:\n",
    "        dose_fct = hill_norm\n",
    "        param_names = [\"V_inf\", \"n\", \"log_ec50_ugmL\"]\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, sharex=True, sharey=True)\n",
    "    axes = np.atleast_2d(axes)\n",
    "    x_range = np.linspace(-2, 2, 101)  # log conc.\n",
    "    \n",
    "                \n",
    "    for i, tcr in enumerate(tcr_subset):\n",
    "        pep_set = df_fit.xs(tcr, level=\"TCR\").index.get_level_values(\"Peptide\").unique()\n",
    "        axes[i, 0].set_ylabel(\"TCR {}\".format(tcr) + \"\\n\" + resp_name)\n",
    "        for jj, pep in enumerate(pep_set):\n",
    "            y_responses = df_data.loc[(tcr, pep), :].values\n",
    "            params = df_fit.loc[(tcr, pep), param_names].values\n",
    "            # Error bars from N_eff\n",
    "            errors = np.sqrt(y_responses * (1.0 - y_responses) / 10.0**df_fit.at[(tcr, pep), \"logN_eff\"])\n",
    "            if np.any(np.isnan(errors)):\n",
    "                errors = 0.0\n",
    "            # Special case: this is the WT peptide, draw in all columns\n",
    "            if pep == \"WT\" or pep[0] == pep[-1]:\n",
    "                for j in range(n_cols):\n",
    "                    clr = colors[\"WT\"]\n",
    "                    axes[i, j].errorbar(x_doses, y_responses, yerr=errors, \n",
    "                        marker=\"o\", ls=\"none\", mfc=clr, mec=clr, label=\"WT\", ecolor=clr)\n",
    "                    axes[i, j].plot(x_range, dose_fct(x_range, params), \n",
    "                        color=clr, ls=\"-\", label=\"WT\")\n",
    "                    \n",
    "            # Regular case: mutated amino acid\n",
    "            else:\n",
    "                # Figure out in which plot to place this peptide based on the \n",
    "                # TCR and the amino acid substitution position\n",
    "                # Infer the color and line style based on the substitute amino acid\n",
    "                clr = colors[pep[2]]\n",
    "                ls = lstyles[pep[2]]\n",
    "                mark = markers[pep[2]]\n",
    "                j = int(pep[1]) - 1\n",
    "                axes[i, j].errorbar(x_doses, y_responses, yerr=errors,\n",
    "                    marker=mark, ls=\"none\", mfc=clr, mec=clr, ecolor=clr)\n",
    "                axes[i, j].plot(x_range, dose_fct(x_range, params), \n",
    "                    color=clr, ls=ls, label=pep[2])\n",
    "    # Final bits of plotting\n",
    "    fig.set_size_inches(2.25 * n_cols, 2.0 * n_rows + 1.0)\n",
    "    for j in range(n_cols):\n",
    "        axes[0, j].set_title(\"Position {} (\".format(j+1) + wt_pep_seq[j] + \")\")\n",
    "        axes[-1, j].set_xlabel(r\"Dose ($\\mu$g/mL)\")\n",
    "    axes[-1, 0].set_xticks(axes[-1, 0].get_xticks())\n",
    "    log_ticks = axes[-1, 0].get_xticklabels()\n",
    "    lbls = list(map(lambda x: r\"$10^{\" + str(x.get_text()) + \"}$\", log_ticks))\n",
    "    axes[-1, 0].set_xticklabels(lbls)\n",
    "    axes[-1, 0].set_xlim([-2.1, 2.1])\n",
    "    fig.suptitle(\"Peptide {}: {}\".format(pep_name, wt_pep_seq))\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig, axes\n",
    "\n",
    "\n",
    "def standalone_legend(*leg_args, **leg_kwargs):\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.set_axis_off()\n",
    "    leg1 = ax1.legend(*leg_args, **leg_kwargs)\n",
    "    fig1.canvas.draw()\n",
    "    # First dummy drawing to get the legend size in inches\n",
    "    leg_width = leg1.get_window_extent().width / fig1.dpi\n",
    "    leg_height = leg1.get_window_extent().height / fig1.dpi\n",
    "    plt.close()\n",
    "\n",
    "    # Now, actual figure which we set at the right size\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(leg_width*1.05, leg_height*1.05)\n",
    "    ax.set_axis_off()\n",
    "    leg = ax.legend(*leg_args, **leg_kwargs)\n",
    "    fig.tight_layout()\n",
    "    return fig, ax, leg\n",
    "\n",
    "# Create a stand-alone legend for amino acid substitutions\n",
    "def full_plots_legend_aa(df_data, **kwargs):\n",
    "    # Prepare line styles\n",
    "    amino_acids = np.unique(list(\"\".join(df_data.index.get_level_values(\"Peptide\").unique())))\n",
    "    amino_acids = sorted([a for a in amino_acids if a.isalpha()])\n",
    "    colors = sns.color_palette(n_colors=len(amino_acids))\n",
    "    colors = {amino_acids[i]:colors[i] for i in range(len(amino_acids))}\n",
    "    colors[\"WT\"] = (0.0,)*3  # black for WT\n",
    "    lstyles = {amino_acids[i]:(\"-\" if i < 10 else \"--\") for i in range(len(amino_acids))}\n",
    "    lstyles[\"WT\"] = \"-\"\n",
    "    markers = {amino_acids[i]:(\"o\" if i < 10 else \"^\") for i in range(len(amino_acids))}\n",
    "    markers[\"WT\"] = \"o\"\n",
    "    \n",
    "    leg_handles = [mpl.lines.Line2D([0], [0], label=\"WT\", ls=\"-\", marker=\"s\", color=colors[\"WT\"])]\n",
    "    for aa in amino_acids:\n",
    "        leg_handles.append(mpl.lines.Line2D([0], [0], label=aa, \n",
    "            ls=lstyles[aa], marker=markers[aa], color=colors[aa]))\n",
    "    return standalone_legend(handles=leg_handles, **kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ag in np.unique(list(tcr_to_ag_map.values())):\n",
    "    figax = full_plots_fits(\n",
    "        df_dose_mskcc.xs(ag, level=\"Antigen\"), \n",
    "        df_ec50_stats_treat[choice_method].xs(ag, level=\"Antigen\"), \n",
    "        pep_name=ag\n",
    "    )\n",
    "    if do_save_plots:\n",
    "        figax[0].savefig(os.path.join(\"figures\", \"dose_response\", \n",
    "            \"mskcc_dose_response_MAP_fits_{}.pdf\".format(ag)), transparent=True)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "figaxes2 = full_plots_legend_aa(df_dose_mskcc.xs(ag, level=\"Antigen\"), \n",
    "                                title=\"Amino acid substitution\", ncols=7)\n",
    "if do_save_plots:\n",
    "    figaxes2[0].savefig(os.path.join(\"figures\", \"dose_response\", \n",
    "            \"mskcc_dose_response_substitutions_legend.pdf\"), transparent=True)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ec50_stats_treat.loc[(\"Neoantigen\", \"7\", [\"A5P\", \"A5Q\", \"A5H\", \"A5Y\", \"A5C\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EC50 to $\\tau$ conversion\n",
    "### Reference point\n",
    "They don't have N4 unfortunately. Let's assume CMV is something like N4. \n",
    "\n",
    "Now, a lot will depend on the choice of that reference: everything will be an antagonist if we choose that too low; nothing will be if we choose too high. So better associate CMV to something too high, so we certainly don't hyperinflate the number of antagonists we predict. \n",
    "\n",
    "No strong need to convert EC50s to tau immediately; to generate model CIs, we will generate a different EC50 for each sample, and these are the EC50s that we will convert to taus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_tau_cmv = 10.0  # Assume similar to N4\n",
    "ref_ec50_cmv = 10.0**df_ec50_stats.loc[(\"CMV\", slice(None), \"WT\"), (choice_method, choice_ec)].min()\n",
    "\n",
    "print(\"Reference: EC50 = {} M, tau = {} s\".format(ref_ec50_cmv, ref_tau_cmv))\n",
    "\n",
    "def ec50_to_tau(ec50: np.float64, ec50_ref=ref_ec50_cmv, tau_ref=ref_tau_cmv):\n",
    "    \"\"\" \n",
    "    Convert an absolute EC50 (in M) to a binding time, \n",
    "    with SIINFEKL = 10 s as a reference. \n",
    "    \"\"\"\n",
    "    return convert_ec50_tau_relative(ec50 / ec50_ref, tau_ref, npow=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to HHAT choice of reference point: EC50 = 3.46e-08 M = 4.2 s\n",
    "print(\"Tau for EC = 3.46 e-8 M:\", ec50_to_tau(3.46e-8))\n",
    "print(\"Tau for EC = 9e-8 M:\", ec50_to_tau(9e-8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mut_ags_taus = (10.0**df_ec50_stats_treat.loc[:, (choice_method, \"log_ec50_M\")]).apply(ec50_to_tau)\n",
    "mut_ags_taus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: obtain error bars on surface antigen densities (Her2 and HLA)\n",
    "Quite easy since I do the same thing for the TCR/CAR predictions: reuse functions!\n",
    "\n",
    "There is also uncertainty on the loading $K_D$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Pulse concentration to antigen number conversion\n",
    "Assuming the peptides load correctly on tumor cells. \n",
    "\n",
    "In other words, loading EC50 of the peptide is the same as for OT1 peptides. Obviously, this is not always true.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model parameters at the same time as loading parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model best fits\n",
    "fit_conc = [\"1uM\", \"1nM\"]\n",
    "analysis_res_fname = \"mcmc_analysis_tcr_car_both_conc.json\"\n",
    "with open(os.path.join(\"results\", \"mcmc\", analysis_res_fname), \"r\") as jfile:\n",
    "    all_results_dicts = json.load(jfile)\n",
    "    del jfile\n",
    "\n",
    "# Go back to linear-scale parameters\n",
    "chosen_kmf = (1, 2, 1)\n",
    "pvec_best = np.asarray(all_results_dicts.get(str(chosen_kmf)).get(\"param_estimates\").get(\"MAP best\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load constant parameter values\n",
    "samples_fname = samples_fname = \"mcmc_results_tcr_car_both_conc.h5\"\n",
    "with h5py.File(os.path.join(\"results\", \"mcmc\", samples_fname), \"r\") as rfile:\n",
    "    data_group = rfile.get(\"data\")\n",
    "    # Load samples too, for CI generation\n",
    "    mcmc_samples_car = rfile.get(\"samples\").get(str(chosen_kmf))[()]\n",
    "    fit_param_names = list(rfile.get(\"samples\").attrs.get(\"param_names\"))\n",
    "    l_conc_mm_params = data_group.get(\"l_conc_mm_params\")[()]\n",
    "    cost_args_loaded = [data_group.get(a)[()]\n",
    "                        for a in data_group.attrs.get(\"cost_args_names\")]\n",
    "    del data_group, rfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply this by the number of MHC per tumor cell\n",
    "def pulse_to_frac_loaded(conc, k_d=l_conc_mm_params[1]):\n",
    "    \"\"\" Compute the fraction of MHC that will be loaded at a pulse conc (in uM)\"\"\"\n",
    "    return michaelis_menten(conc, 1.0, k_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Load surface molecule numbers\n",
    "\n",
    "We do not want to use the single-cell data because the model relies on an average APC and an average T cell. But there is still some uncertainty on the average antigen levels, so for parameters $L^T$, $L^C$, assume a log-normal distribution (Gaussian in log scale) centered on the mean and with variance equal to the variance on the mean estimator, as reported in the summary statistics. \n",
    "\n",
    "Then, when generating model CI, also include these ligand number distributions as sources of uncertainty: sample from them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all CAR and TCR antigen numbers on the tumor lines used for each TCR line\n",
    "molec_counts_filename = \"data/surface_counts/surface_molecule_summary_stats.h5\"\n",
    "mtc = \"Geometric mean\"\n",
    "\n",
    "# Surface area of cells, relative to E2aPBX\n",
    "# Unsure about surface area of PC9 and BEAS2B, using 1.0\n",
    "size_factors = {\"E2APBX\":1.0, \"Nalm6\":2.0, \"PC9\":1.0, \"BEAS2B\":1.0}\n",
    "\n",
    "# Get MHC and tumor antigen levels, as well as receptor numbers and loading EC50. \n",
    "# For each, also get the geometric mean, and the standard deviation of the mean estimator\n",
    "# TCR, CAR, CD19, MHC, and loading EC50 parameters\n",
    "molec_loads = load_tcr_car_molec_numbers_ci(\n",
    "    molec_counts_filename, mtc, tumor_type=\"PC9\",\n",
    "    tcell_type=\"OT1_CAR\", tumor_antigen=\"Her2\", \n",
    "    data_fold=\"data/\"\n",
    ")\n",
    "# Means\n",
    "cell_info_means = {\n",
    "    #\"tcr\": molec_loads[0],  # This is the default used for TCR/CAR fits\n",
    "    #\"car\": molec_loads[1],  # This is the default too\n",
    "    \"car_ag\": molec_loads[2] / size_factors[\"PC9\"],\n",
    "    \"l_conc_mm_params\": [molec_loads[3][0] / size_factors['PC9'], molec_loads[3][1]]\n",
    "}\n",
    "# Standard deviations and #dofs for sampling from Student's t distribution\n",
    "all_stds, all_ndofs = molec_loads[5], molec_loads[6]\n",
    "\n",
    "print(cell_info_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_hdf(molec_counts_filename, key=\"surface_numbers_stats\")[\"Geometric mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: model predictions for all peptides with MCMC\n",
    "## Implementation\n",
    "Not much more complicated to account for uncertainty in $L^T$, $L^C$, and $\\tau^T$: for each model parameter sample, also sample a ligand density (same for all peptides in that sample), and a $\\tau^T$ for each peptide. Repeat many times to get good statistics on the FC predictions of each antigen, and ultimately on the fractions of antigen types. \n",
    "\n",
    "Still, we will need custom code that samples all these distributions for each replicate; can't reuse the `confidence_predictions_car_antagonism function`, because it only samples parameters. But we can reuse the model panel functions: `apply antag_ratio_panel_tcr_car_numbers` to each sample, after adjusting the ligand densities in the arguments passed to it for each parameter sample. \n",
    "\n",
    "Most importantly, include uncertainty in the peptides EC50s. Need to use EC50 and pulse concentrations as Index levels in the DataFrame concatenating all the results, becase these will correspond to varying taus and ligand numbers, respectively, for each sample of the antigen numbers, loading EC50, and peptide EC50s. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis function\n",
    "We will want to count fractions of antagonists, agonists, null peptides, so we want to return model values from all individual MCMC samples here, not just aggregated statistics. So define a new analysis function that just concatenates the original samples and aggregate statistics in separate columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_samples_stats(df_samples, ser_best):\n",
    "    # Compute usual statistics\n",
    "    df_stats = compute_stats_ci(df_samples, ser_best)\n",
    "    \n",
    "    # Then, return all samples too\n",
    "    df_samples_stats = pd.concat({\"stats\":df_stats, \"samples\":df_samples}, names=[\"Feature\"], axis=1)\n",
    "    return df_samples_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dens_name = \"TCR_Antigen_Pulse_uM\"\n",
    "\n",
    "# Prepare the DataFrame with relevant log10(EC50) of peptides\n",
    "df_logec50_info = pd.DataFrame(0.0, index=df_ec50_stats_treat.index, \n",
    "                    columns=pd.Index([\"estimator\", \"std\"], name=\"Quantity\"))\n",
    "df_logec50_info[\"estimator\"] = df_ec50_stats_treat.loc[:, (choice_method, \"log_ec50_M\")]\n",
    "df_logec50_info[\"std\"] = df_ec50_stats_treat.loc[:, (choice_std, \"log_ec50_M\")]\n",
    "\n",
    "# Prepare the pandas MultiIndex specifying conditions to predict\n",
    "# Do not include TCR_Antigen_tau, since this will change\n",
    "# at each CI sample; last level should be pulse concentration, \n",
    "# previous levels should specify the peptide to recover its\n",
    "# logEC50s' mean and standard deviation. \n",
    "pulse_concs = [1e-3, 1e0]  # predict 1 uM and 1 nM\n",
    "cond_index_mskcc = (pd.concat({k:df_logec50_info for k in pulse_concs}, names=[dens_name])\n",
    "         .index.reorder_levels([\"Antigen\", \"TCR\", \"Peptide\", dens_name]).sort_values())\n",
    "\n",
    "# For all peptides, predict antagonism\n",
    "seedseq = np.random.SeedSequence(0xa85966d4fc40a221f8f9eacfc5a98cbe)\n",
    "\n",
    "# Cell ligand numbers mean estimators, standard deviations, n_dofs\n",
    "# were loaded above: cell_info_means, all_stds, all_ndofs\n",
    "# Compute CI. Args: model_panel, psamples, pbest, grid_pt, cond_index, pep_log10ec50s\n",
    "# kwargs: analysis_fct, other_args, seed, n_samp, tcr_pulse_lvl, cell_info, molec_stds, molec_dofs\n",
    "df_antagonism_mut, pep_logec50_samples = confidence_predictions_car_antagonism_ligands(\n",
    "    antag_ratio_panel_tcr_car, \n",
    "    mcmc_samples_car,\n",
    "    pvec_best,\n",
    "    chosen_kmf,\n",
    "    cond_index_mskcc, \n",
    "    df_logec50_info,\n",
    "    analysis_fct=concatenate_samples_stats,#compute_stats_ci, \n",
    "    other_args=cost_args_loaded,\n",
    "    seed=seedseq,\n",
    "    n_samp=n_boot, \n",
    "    tcr_pulse_lvl=dens_name,\n",
    "    cell_info=cell_info_means, \n",
    "    molec_stds=all_stds,\n",
    "    molec_dofs=all_ndofs, \n",
    "    ec50_tau_refs=(ref_ec50_cmv, ref_tau_cmv)\n",
    ")\n",
    "\n",
    "# Put back nice pulse concentration labels\n",
    "df_antagonism_mut = df_antagonism_mut.rename(write_conc_uM, level=dens_name)\n",
    "df_antagonism_mut = df_antagonism_mut.dropna()\n",
    "df_antagonism_mut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "agdens_palette = {\"1uM\": perturb_palette[\"None\"], \"1nM\": perturb_palette[\"AgDens\"]}\n",
    "nice_pulse_name = \"TCR Ag pulse\"\n",
    "plotDf = np.log2(df_antagonism_mut[\"stats\"])\n",
    "new_lvl = \"Antigen & mutation\"\n",
    "plotDf[new_lvl] = (plotDf.index.get_level_values(\"Antigen\") \n",
    "                    + \"-\" + plotDf.index.get_level_values(\"Peptide\"))\n",
    "plotDf = plotDf.set_index(new_lvl, append=True)\n",
    "plotDf = (plotDf.groupby([new_lvl, dens_name])  # Average across receptors\n",
    "            .mean().sort_values(\"best\")\n",
    "         )\n",
    "plotDf.index = plotDf.index.rename(names=nice_pulse_name, level=dens_name)\n",
    "nice_fc_label = r\"$\\mathrm{FC}_{TCR/CAR}$\"\n",
    "plotDf = plotDf.rename(mapper={\"best\": nice_fc_label}, axis=1)\n",
    "\n",
    "facet = sns.FacetGrid(\n",
    "    data=plotDf.reset_index(), \n",
    "    hue=nice_pulse_name, \n",
    "    palette=agdens_palette, \n",
    "    hue_order=[\"1uM\", \"1nM\"],\n",
    "    col=nice_pulse_name, \n",
    "    col_order=[\"1uM\", \"1nM\"],\n",
    ")\n",
    "facet.map(sns.histplot, nice_fc_label, bins=20)\n",
    "#for ax in facet.axes.flat:\n",
    "#    ax.axvline(0.0, ls=\"--\", color=\"k\", lw=1.0)\n",
    "facet.fig.set_size_inches(facet.fig.get_size_inches()[0], facet.fig.get_size_inches()[1])\n",
    "change_log_ticks(facet.axes.flat[0], which=\"x\")\n",
    "change_log_ticks(facet.axes.flat[1], which=\"x\")\n",
    "\n",
    "# Annotate with the fraction of antigens below FC = 1.0\n",
    "pulse_concs = [\"1uM\", \"1nM\"]\n",
    "for i in range(2):\n",
    "    conc = pulse_concs[i]\n",
    "    xlims =  facet.axes.flat[i].get_xlim()\n",
    "    facet.axes.flat[i].set_xlim(xlims[0]-0.1, xlims[1])\n",
    "    frac_below = (np.sum(df_antagonism_mut.xs(conc, level=dens_name)[(\"stats\", \"best\")] < 1.0) \n",
    "                  / df_antagonism_mut.xs(conc, level=dens_name)[(\"stats\", \"best\")].count())\n",
    "    facet.axes.flat[i].axvline(0.0, ls=\"--\", color=\"grey\", lw=1.0)\n",
    "    ymax = facet.axes.flat[i].get_ylim()[1]\n",
    "    facet.axes.flat[i].annotate(\"{:.1f} %\".format(100.0*frac_below), xy=(-0.075, ymax*.98), \n",
    "                                va=\"top\", ha=\"right\")\n",
    "    facet.axes.flat[i].annotate(\"{:.1f} %\".format(100.0*(1.0 - frac_below)), xy=(0.075, ymax*.98), \n",
    "                                va=\"top\", ha=\"left\")\n",
    "facet.axes.flat[0].set_ylabel(\"Number of peptides (#)\")\n",
    "\n",
    "facet.figure.tight_layout()\n",
    "if do_save_plots:\n",
    "    facet.figure.savefig(\"figures/extra_predictions/mskcc_antagonism_fc_distributions_pc9.pdf\", \n",
    "                      transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute the fraction of agonists, antagonists, null peptides for each TCR and antigen\n",
    "df_pc9_samples = np.log2(df_antagonism_mut[\"samples\"].xs(\"1uM\", level=dens_name))\n",
    "null_thresh = 1.0  # log2 fold-change\n",
    "totals_peps = df_pc9_samples.groupby([\"Antigen\", \"TCR\"]).count()\n",
    "df_fracs_samples = pd.concat({\n",
    "    \"agonists\": (df_pc9_samples >= null_thresh).groupby([\"Antigen\", \"TCR\"]).sum() / totals_peps, \n",
    "    \"antagonists\": (df_pc9_samples <= -null_thresh).groupby([\"Antigen\", \"TCR\"]).sum() / totals_peps, \n",
    "    \"null\": (np.abs(df_pc9_samples) < null_thresh).groupby([\"Antigen\", \"TCR\"]).sum() / totals_peps\n",
    "}, names=[\"peptide_type\"]).sort_index(level=[\"Antigen\", \"TCR\"])\n",
    "df_fracs_samples.columns = df_fracs_samples.columns.astype(np.int64)\n",
    "\n",
    "df_antag_best = np.log2(df_antagonism_mut[(\"stats\", \"best\")].xs(\"1uM\", level=dens_name))\n",
    "totals_peps_best = df_antag_best.groupby([\"Antigen\", \"TCR\"]).count()\n",
    "df_fracs_best = pd.concat({\n",
    "    \"agonists\": (df_antag_best >= null_thresh).groupby([\"Antigen\", \"TCR\"]).sum() / totals_peps_best, \n",
    "    \"antagonists\": (df_antag_best <= -null_thresh).groupby([\"Antigen\", \"TCR\"]).sum() / totals_peps_best, \n",
    "    \"null\": (np.abs(df_antag_best) < null_thresh).groupby([\"Antigen\", \"TCR\"]).sum() / totals_peps_best\n",
    "}, names=[\"peptide_type\"]).sort_index(level=[\"Antigen\", \"TCR\"])\n",
    "\n",
    "# Compute statistics of agonist, antagonist, null fractions across MCMC samples (columns)\n",
    "df_fracs_samples_stats = pd.concat({\n",
    "    \"mean\": df_fracs_samples.mean(axis=1), \n",
    "    \"median\": df_fracs_samples.median(axis=1),\n",
    "    \"percentile_2.5\": df_fracs_samples.quantile(q=0.025, axis=1), \n",
    "    \"percentile_97.5\": df_fracs_samples.quantile(q=0.975, axis=1), \n",
    "    \"best\": df_fracs_best\n",
    "}, names=[\"stats\"], axis=1)\n",
    "df_fracs_samples_display = (df_fracs_samples_stats.unstack(\"peptide_type\")\n",
    "                .reorder_levels([\"peptide_type\", \"stats\"], axis=1).sort_index(axis=1))\n",
    "df_fracs_samples_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fractions vs WT peptide EC50\n",
    "def plot_fractions(df_fracs_stats, df_logec50s_estim):\n",
    "    fig, ax = plt.subplots()\n",
    "    pep_idx = df_logec50s_estim.sort_values().index\n",
    "    assert pep_idx.names == [\"Antigen\", \"TCR\"]\n",
    "    x_vals = 1.0 / 10.0**df_logec50s_estim.loc[pep_idx]\n",
    "    colmap = {\"agonists\": \"xkcd:goldenrod\", \"antagonists\": \"purple\", \"null\": \"grey\"}\n",
    "    for kind in [\"agonists\", \"antagonists\", \"null\"]:\n",
    "        y_vals = df_fracs_stats.loc[pep_idx, (kind, \"median\")]\n",
    "        y_lower = (y_vals - df_fracs_stats.loc[pep_idx, (kind, \"percentile_2.5\")]).clip(lower=0.0)\n",
    "        y_upper = (df_fracs_stats.loc[pep_idx, (kind, \"percentile_97.5\")] - y_vals).clip(lower=0.0)\n",
    "        ax.errorbar(x_vals, y_vals, yerr=[y_lower, y_upper], color=colmap[kind], label=kind, lw=2.5)\n",
    "        #ax.plot(x_vals, y_vals, color=colmap[kind], label=kind)\n",
    "    for pep in pep_idx:\n",
    "        ax.annotate(pep, (x_vals.loc[pep], y_vals.loc[pep]), fontsize=8)\n",
    "    ax.set(xlabel=r\"p${}^{\\mathrm{WT}}$ 1/EC50 ($\\mathrm{M^{-1}}$)\", ylabel=\"Fraction\", xscale=\"log\")\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    return fig, ax\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figax = plot_fractions(df_fracs_samples_display, df_logec50_info.xs(\"WT\", level=\"Peptide\")[\"estimator\"])\n",
    "figax[1].set_title(\"Including gp100, TCR 4\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Also try without gp100, TCR 4 which has a lot of null (experimental issue?)\n",
    "#figax = plot_fractions(df_fracs_samples_display.drop((\"gp100\", \"4\")), \n",
    "#        df_logec50_info.xs(\"WT\", level=\"Peptide\")[\"estimator\"].drop((\"gp100\", \"4\")))\n",
    "#figax[1].set_title(\"Without gp100, TCR 4\")\n",
    "#plt.show()\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions\n",
    "if null_thresh > 0.25:\n",
    "    res_file_name = os.path.join(\"results\", \"for_plots\", \n",
    "        \"mskcc_antagonism_fc_predictions_corrected_revised.h5\")\n",
    "else:\n",
    "    res_file_name = os.path.join(\"results\", \"for_plots\", \n",
    "        \"mskcc_antagonism_fc_predictions_corrected_revised_nonull.h5\")\n",
    "if do_save_outputs:\n",
    "    df_antagonism_mut[\"stats\"].to_hdf(res_file_name, key=\"fc_stats\")\n",
    "    samples_df_to_save = df_antagonism_mut[\"samples\"]\n",
    "    samples_df_to_save.columns = samples_df_to_save.columns.astype(np.int64)\n",
    "    samples_df_to_save.to_hdf(res_file_name, key=\"fc_samples\")\n",
    "    df_fracs_samples_stats.to_hdf(res_file_name, key=\"fracs_stats\")\n",
    "    df_fracs_samples.to_hdf(res_file_name, key=\"fracs_samples\")\n",
    "    df_ec50_stats_treat[[choice_method, choice_std]].to_hdf(res_file_name, key=\"EC50_fits\")\n",
    "    pep_logec50_samples.to_hdf(res_file_name, key=\"EC50_samples\")\n",
    "    print(\"Saved results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
